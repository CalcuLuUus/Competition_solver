{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bfd032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 原始训练数据 (train.csv) ---\n",
      "  buyer_country_id  buyer_admin_id  item_id    create_order_time  irank\n",
      "0               xx          489859        1  2018-04-11 03:28:02      9\n",
      "1               xx         2567786        2  2018-04-14 08:24:26     26\n",
      "2               xx         3408746        3  2018-04-17 02:11:56      7\n",
      "3               xx         2801580        4  2018-04-20 10:11:17      3\n",
      "4               xx         1348149        5  2018-04-17 10:49:05      4\n",
      "\n",
      "--- 原始商品属性数据 (item_attr.csv) ---\n",
      "   item_id  cate_id  store_id  item_price\n",
      "0   140446     1413     11822           1\n",
      "1   403593     2313     19712           1\n",
      "2   252621     1682      6622           1\n",
      "3   204530     1413     11822           1\n",
      "4   340076      181     24403           1\n",
      "(6989817, 5)\n",
      "(1924269, 4)\n",
      "--- 1. 数据合并结果 ---\n",
      "合并后表格的维度: (6989817, 8)\n",
      "合并后表格的前5行:\n",
      "  buyer_country_id  buyer_admin_id  item_id    create_order_time  irank  \\\n",
      "0               xx          489859        1  2018-04-11 03:28:02      9   \n",
      "1               xx         2567786        2  2018-04-14 08:24:26     26   \n",
      "2               xx         3408746        3  2018-04-17 02:11:56      7   \n",
      "3               xx         2801580        4  2018-04-20 10:11:17      3   \n",
      "4               xx         1348149        5  2018-04-17 10:49:05      4   \n",
      "\n",
      "   cate_id  store_id  item_price  \n",
      "0   2228.0    9694.0      4491.0  \n",
      "1   3667.0    4364.0      2751.0  \n",
      "2    153.0    8085.0       656.0  \n",
      "3   3359.0    3345.0      2501.0  \n",
      "4   1156.0    1892.0       589.0  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# --- 加载数据 ---\n",
    "# 请将下面的StringIO替换为你的文件名，例如 'train.csv'\n",
    "train_df = pd.read_csv('data/Antai_hackathon_train.csv')\n",
    "attr_df = pd.read_csv('data/Antai_hackathon_attr.csv')\n",
    "\n",
    "# 检查数据加载情况\n",
    "print(\"--- 原始训练数据 (train.csv) ---\")\n",
    "print(train_df.head())\n",
    "print(\"\\n--- 原始商品属性数据 (item_attr.csv) ---\")\n",
    "print(attr_df.head())\n",
    "\n",
    "merged_df = pd.merge(train_df, attr_df, on='item_id', how='left')\n",
    "\n",
    "print(train_df.shape)\n",
    "print(attr_df.shape)\n",
    "\n",
    "# 显示合并后的表格信息\n",
    "print(\"--- 1. 数据合并结果 ---\")\n",
    "print(\"合并后表格的维度:\", merged_df.shape)\n",
    "print(\"合并后表格的前5行:\")\n",
    "print(merged_df.head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f26a15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buyer_country_id</th>\n",
       "      <th>buyer_admin_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>create_order_time</th>\n",
       "      <th>irank</th>\n",
       "      <th>cate_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xx</td>\n",
       "      <td>489859</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-11 03:28:02</td>\n",
       "      <td>9</td>\n",
       "      <td>2228.0</td>\n",
       "      <td>9694.0</td>\n",
       "      <td>4491.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xx</td>\n",
       "      <td>2567786</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-14 08:24:26</td>\n",
       "      <td>26</td>\n",
       "      <td>3667.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>2751.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xx</td>\n",
       "      <td>3408746</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-17 02:11:56</td>\n",
       "      <td>7</td>\n",
       "      <td>153.0</td>\n",
       "      <td>8085.0</td>\n",
       "      <td>656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xx</td>\n",
       "      <td>2801580</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-20 10:11:17</td>\n",
       "      <td>3</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>3345.0</td>\n",
       "      <td>2501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xx</td>\n",
       "      <td>1348149</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-04-17 10:49:05</td>\n",
       "      <td>4</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985354</th>\n",
       "      <td>xx</td>\n",
       "      <td>1305397</td>\n",
       "      <td>7580905</td>\n",
       "      <td>2018-04-16 02:33:33</td>\n",
       "      <td>3</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>76810.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985355</th>\n",
       "      <td>xx</td>\n",
       "      <td>1305397</td>\n",
       "      <td>7580905</td>\n",
       "      <td>2018-04-16 02:33:33</td>\n",
       "      <td>2</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>76810.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985356</th>\n",
       "      <td>xx</td>\n",
       "      <td>1305397</td>\n",
       "      <td>7580905</td>\n",
       "      <td>2018-04-16 02:33:33</td>\n",
       "      <td>7</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>76810.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989120</th>\n",
       "      <td>xx</td>\n",
       "      <td>1743518</td>\n",
       "      <td>7585013</td>\n",
       "      <td>2018-04-21 15:28:54</td>\n",
       "      <td>12</td>\n",
       "      <td>320.0</td>\n",
       "      <td>76684.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989121</th>\n",
       "      <td>xx</td>\n",
       "      <td>1743518</td>\n",
       "      <td>7585013</td>\n",
       "      <td>2018-04-21 15:28:54</td>\n",
       "      <td>10</td>\n",
       "      <td>320.0</td>\n",
       "      <td>76684.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2415585 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        buyer_country_id  buyer_admin_id  item_id    create_order_time  irank  \\\n",
       "0                     xx          489859        1  2018-04-11 03:28:02      9   \n",
       "1                     xx         2567786        2  2018-04-14 08:24:26     26   \n",
       "2                     xx         3408746        3  2018-04-17 02:11:56      7   \n",
       "3                     xx         2801580        4  2018-04-20 10:11:17      3   \n",
       "4                     xx         1348149        5  2018-04-17 10:49:05      4   \n",
       "...                  ...             ...      ...                  ...    ...   \n",
       "6985354               xx         1305397  7580905  2018-04-16 02:33:33      3   \n",
       "6985355               xx         1305397  7580905  2018-04-16 02:33:33      2   \n",
       "6985356               xx         1305397  7580905  2018-04-16 02:33:33      7   \n",
       "6989120               xx         1743518  7585013  2018-04-21 15:28:54     12   \n",
       "6989121               xx         1743518  7585013  2018-04-21 15:28:54     10   \n",
       "\n",
       "         cate_id  store_id  item_price  \n",
       "0         2228.0    9694.0      4491.0  \n",
       "1         3667.0    4364.0      2751.0  \n",
       "2          153.0    8085.0       656.0  \n",
       "3         3359.0    3345.0      2501.0  \n",
       "4         1156.0    1892.0       589.0  \n",
       "...          ...       ...         ...  \n",
       "6985354   2514.0   76810.0       101.0  \n",
       "6985355   2514.0   76810.0       101.0  \n",
       "6985356   2514.0   76810.0       101.0  \n",
       "6989120    320.0   76684.0        81.0  \n",
       "6989121    320.0   76684.0        81.0  \n",
       "\n",
       "[2415585 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.groupby('buyer_admin_id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d668f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载完成。\n",
      "训练集记录数: 6989817\n",
      "测试集记录数: 140380\n",
      "\n",
      "正在计算商品热度...\n",
      "Top 30 热门商品计算完成:\n",
      "[7493101, 516873, 3964264, 7557509, 7482805, 3058048, 426022, 1872817, 413606, 6162363, 648691, 797627, 5421409, 1266501, 584059, 4163903, 928637, 564243, 7538392, 2982899, 7533383, 959326, 34624, 5759221, 560251, 5644811, 5378792, 7324348, 691497, 2548432]\n",
      "\n",
      "正在为测试集用户生成推荐...\n",
      "需要为 10576 名测试用户生成预测。\n",
      "\n",
      "提交文件 'global_popularity_baseline.csv' 已成功生成！\n",
      "文件预览:\n",
      "   buyer_admin_id  predict 1  predict 2  predict 3  predict 4  predict 5  \\\n",
      "0         6664334    7493101     516873    3964264    7557509    7482805   \n",
      "1         6394777    7493101     516873    3964264    7557509    7482805   \n",
      "2         1746935    7493101     516873    3964264    7557509    7482805   \n",
      "3         5828988    7493101     516873    3964264    7557509    7482805   \n",
      "4          421713    7493101     516873    3964264    7557509    7482805   \n",
      "\n",
      "   predict 6  predict 7  predict 8  predict 9  ...  predict 21  predict 22  \\\n",
      "0    3058048     426022    1872817     413606  ...     7533383      959326   \n",
      "1    3058048     426022    1872817     413606  ...     7533383      959326   \n",
      "2    3058048     426022    1872817     413606  ...     7533383      959326   \n",
      "3    3058048     426022    1872817     413606  ...     7533383      959326   \n",
      "4    3058048     426022    1872817     413606  ...     7533383      959326   \n",
      "\n",
      "   predict 23  predict 24  predict 25  predict 26  predict 27  predict 28  \\\n",
      "0       34624     5759221      560251     5644811     5378792     7324348   \n",
      "1       34624     5759221      560251     5644811     5378792     7324348   \n",
      "2       34624     5759221      560251     5644811     5378792     7324348   \n",
      "3       34624     5759221      560251     5644811     5378792     7324348   \n",
      "4       34624     5759221      560251     5644811     5378792     7324348   \n",
      "\n",
      "   predict 29  predict 30  \n",
      "0      691497     2548432  \n",
      "1      691497     2548432  \n",
      "2      691497     2548432  \n",
      "3      691497     2548432  \n",
      "4      691497     2548432  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. 加载数据 ---\n",
    "# 请确保文件名与你的本地文件一致\n",
    "try:\n",
    "    train_df = pd.read_csv('data/Antai_hackathon_train.csv')\n",
    "    test_df = pd.read_csv('data/dianshang_test.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"错误：请确保 train.csv 和 test_without_last.csv 文件在当前目录下！\")\n",
    "    # 为了让代码能继续演示，这里使用一个空的DataFrame\n",
    "    # 在你的环境中，如果文件存在，这部分代码不会执行\n",
    "    train_df = pd.DataFrame({'item_id': [1, 1, 2, 3, 2, 1]})\n",
    "    test_df = pd.DataFrame({'buyer_admin_id': [1001, 1002, 1001]})\n",
    "\n",
    "\n",
    "print(\"数据加载完成。\")\n",
    "print(f\"训练集记录数: {len(train_df)}\")\n",
    "print(f\"测试集记录数: {len(test_df)}\")\n",
    "\n",
    "\n",
    "# --- 2. 计算全局商品热度 ---\n",
    "# 使用 value_counts() 可以非常高效地计算每个 item_id 出现的次数\n",
    "print(\"\\n正在计算商品热度...\")\n",
    "item_popularity = train_df['item_id'].value_counts()\n",
    "\n",
    "# 获取热度最高的前30个商品\n",
    "top_30_items = item_popularity.head(30).index.tolist()\n",
    "\n",
    "print(\"Top 30 热门商品计算完成:\")\n",
    "print(top_30_items)\n",
    "\n",
    "\n",
    "# --- 3. 为测试集用户生成推荐列表并创建提交文件 ---\n",
    "print(\"\\n正在为测试集用户生成推荐...\")\n",
    "# 获取测试集中所有不重复的用户ID\n",
    "test_user_ids = test_df['buyer_admin_id'].unique()\n",
    "print(f\"需要为 {len(test_user_ids)} 名测试用户生成预测。\")\n",
    "\n",
    "# 准备一个列表来存储最终的提交结果\n",
    "submission_data = []\n",
    "\n",
    "# 将Top 30商品列表转换为字符串，用逗号连接，这样效率更高\n",
    "top_30_items_str = \",\".join(map(str, top_30_items))\n",
    "\n",
    "for user_id in test_user_ids:\n",
    "    # 对于全局热度模型，每个用户的推荐列表都是一样的\n",
    "    # 格式为：[用户ID, 预测商品1, 预测商品2, ...]\n",
    "    # 为了直接写入CSV，我们构建一行字符串\n",
    "    submission_data.append([user_id] + top_30_items)\n",
    "\n",
    "# --- 4. 保存提交文件 ---\n",
    "# 定义提交文件的列名\n",
    "columns = ['buyer_admin_id'] + [f'predict {i+1}' for i in range(30)]\n",
    "\n",
    "# 创建DataFrame\n",
    "submission_df = pd.DataFrame(submission_data, columns=columns)\n",
    "\n",
    "# 保存为CSV文件，注意 index=False 参数是必须的，否则会多出一列索引\n",
    "# 比赛要求的文件名为 username.csv, 请自行修改'global_popularity_baseline.csv'\n",
    "submission_filename = 'global_popularity_baseline.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"\\n提交文件 '{submission_filename}' 已成功生成！\")\n",
    "print(\"文件预览:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8507e504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载数据...\n",
      "开始构建商品转移矩阵...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. 加载数据 ---\n",
    "print(\"正在加载数据...\")\n",
    "try:\n",
    "    train_df = pd.read_csv('data/Antai_hackathon_train.csv')\n",
    "    test_df = pd.read_csv('data/dianshang_test.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"错误：请确保 train.csv 和 test_.csv 文件在当前目录下！\")\n",
    "\n",
    "\n",
    "# --- 2. 构建商品转移矩阵 ---\n",
    "print(\"开始构建商品转移矩阵...\")\n",
    "\n",
    "# 确保时间列是datetime类型，并按用户和时间排序\n",
    "train_df['create_order_time'] = pd.to_datetime(train_df['create_order_time'])\n",
    "train_df = train_df.sort_values(by=['buyer_admin_id', 'create_order_time'])\n",
    "\n",
    "# 使用defaultdict来高效地存储转移关系\n",
    "# 格式: {item_A: {item_B: count, item_C: count}, ...}\n",
    "transition_matrix = defaultdict(lambda: defaultdict(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9618eb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users: 100%|██████████| 483117/483117 [00:16<00:00, 29535.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转移矩阵构建完成。\n",
      "正在计算全局热度榜单 (用于回退)...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 使用tqdm来显示进度条\n",
    "# 我们按用户分组，然后处理每个用户的购买序列\n",
    "for user_id, user_group in tqdm(train_df.groupby('buyer_admin_id'), desc=\"Processing users\"):\n",
    "    # 将用户的购买商品ID转换为列表\n",
    "    item_sequence = user_group['item_id'].tolist()\n",
    "    # 遍历序列，创建(前一个商品, 后一个商品)的对\n",
    "    for i in range(len(item_sequence) - 1):\n",
    "        prev_item = item_sequence[i]\n",
    "        next_item = item_sequence[i+1]\n",
    "        transition_matrix[prev_item][next_item] += 1\n",
    "\n",
    "print(\"转移矩阵构建完成。\")\n",
    "\n",
    "# --- 3. 准备回退策略：全局热度榜单 ---\n",
    "print(\"正在计算全局热度榜单 (用于回退)...\")\n",
    "item_popularity = train_df['item_id'].value_counts()\n",
    "global_top_30_items = item_popularity.head(30).index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27408d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在为测试用户生成推荐列表...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4. 为测试用户生成推荐 ---\n",
    "print(\"正在为测试用户生成推荐列表...\")\n",
    "\n",
    "# 找到每个测试用户的最后一次购买记录\n",
    "test_df['create_order_time'] = pd.to_datetime(test_df['create_order_time'])\n",
    "last_purchases = test_df.sort_values('create_order_time').drop_duplicates('buyer_admin_id', keep='last')\n",
    "user_last_item_map = dict(zip(last_purchases['buyer_admin_id'], last_purchases['item_id']))\n",
    "all_test_users = test_df['buyer_admin_id'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9406a089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 10576/10576 [00:01<00:00, 7915.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "提交文件 'item_cf_baseline.csv' 已成功生成！\n",
      "文件预览:\n",
      "   buyer_admin_id  predict 1  predict 2  predict 3  predict 4  predict 5  \\\n",
      "0         6664334    5736363    5881751    4091904     158258    2695682   \n",
      "1         6394777    4430243    1642080    2391712    7493101     516873   \n",
      "2         1746935    7493101     516873    3964264    7557509    7482805   \n",
      "3         5828988     926095    7493101     516873    3964264    7557509   \n",
      "4          421713    3517157     828371    4105328    3537214    3812200   \n",
      "\n",
      "   predict 6  predict 7  predict 8  predict 9  ...  predict 21  predict 22  \\\n",
      "0    6886784    4435110    6207830    1305003  ...     3964264     7557509   \n",
      "1    3964264    7557509    7482805    3058048  ...      564243     7538392   \n",
      "2    3058048     426022    1872817     413606  ...     7533383      959326   \n",
      "3    7482805    3058048     426022    1872817  ...     2982899     7533383   \n",
      "4    6831580    4883526    4120858    2336195  ...     5594492     3555140   \n",
      "\n",
      "   predict 23  predict 24  predict 25  predict 26  predict 27  predict 28  \\\n",
      "0     7482805     3058048      426022     1872817      413606     6162363   \n",
      "1     2982899     7533383      959326       34624     5759221      560251   \n",
      "2       34624     5759221      560251     5644811     5378792     7324348   \n",
      "3      959326       34624     5759221      560251     5644811     5378792   \n",
      "4     6037435     3728566     7493101      516873     3964264     7557509   \n",
      "\n",
      "   predict 29  predict 30  \n",
      "0      648691      797627  \n",
      "1     5644811     5378792  \n",
      "2      691497     2548432  \n",
      "3     7324348      691497  \n",
      "4     7482805     3058048  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "submission_data = []\n",
    "\n",
    "for user_id in tqdm(all_test_users, desc=\"Generating predictions\"):\n",
    "    recommendations = []\n",
    "    \n",
    "    # 获取该用户的最后购买商品\n",
    "    last_item = user_last_item_map.get(user_id)\n",
    "    \n",
    "    # 如果该用户有最后购买记录，并且该商品在我们的转移矩阵中\n",
    "    if last_item and last_item in transition_matrix:\n",
    "        # 从转移矩阵中获取候选推荐\n",
    "        candidates = transition_matrix[last_item]\n",
    "        # 按购买次数降序排序\n",
    "        sorted_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)\n",
    "        # 提取商品ID\n",
    "        recommendations = [item_id for item_id, count in sorted_candidates]\n",
    "\n",
    "    # --- 回退和补充逻辑 ---\n",
    "    # 如果个性化推荐不足30个，或根本没有个性化推荐\n",
    "    if len(recommendations) < 30:\n",
    "        # 使用全局热度榜单来补充\n",
    "        # 创建一个已推荐商品的集合，用于快速去重\n",
    "        rec_set = set(recommendations)\n",
    "        for popular_item in global_top_30_items:\n",
    "            if popular_item not in rec_set:\n",
    "                recommendations.append(popular_item)\n",
    "            # 当推荐列表达到30个时，停止补充\n",
    "            if len(recommendations) >= 30:\n",
    "                break\n",
    "    \n",
    "    # 截取最终的Top 30\n",
    "    final_recommendations = recommendations[:30]\n",
    "    submission_data.append([user_id] + final_recommendations)\n",
    "\n",
    "# --- 5. 保存提交文件 ---\n",
    "columns = ['buyer_admin_id'] + [f'predict {i+1}' for i in range(30)]\n",
    "submission_df = pd.DataFrame(submission_data, columns=columns)\n",
    "\n",
    "submission_filename = 'item_cf_baseline.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"\\n提交文件 '{submission_filename}' 已成功生成！\")\n",
    "print(\"文件预览:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b8ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载数据...\n",
      "正在准备用户购买历史字典...\n",
      "开始构建物品相似度矩阵 (此过程可能需要较长时间)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算共现次数和热度: 100%|██████████| 483117/483117 [01:46<00:00, 4537.27it/s] \n",
      "计算余弦相似度: 100%|██████████| 1852415/1852415 [05:33<00:00, 5557.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "物品相似度矩阵构建完成。\n",
      "正在计算全局热度榜单 (用于回退)...\n",
      "正在为测试用户生成推荐列表...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 10576/10576 [00:55<00:00, 189.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "提交文件 'classic_item_cf_baseline.csv' 已成功生成！\n",
      "文件预览:\n",
      "   buyer_admin_id  predict 1  predict 2  predict 3  predict 4  predict 5  \\\n",
      "0         6664334    3783312    3759092    3756841    3908460    3725537   \n",
      "1         6394777    7254114    6541314    7173068    4824270    1802691   \n",
      "2         1746935    3184786    2058901        153     453414     454708   \n",
      "3         5828988    6127880    5159147      20494    4083696    4338709   \n",
      "4          421713    6714817    5660680    2432746    6544645    4216322   \n",
      "\n",
      "   predict 6  predict 7  predict 8  predict 9  ...  predict 21  predict 22  \\\n",
      "0    3696977    3728430    3784302    3699976  ...     6362205     1889135   \n",
      "1    1223367     839668    5313566    5368075  ...      797410     5444071   \n",
      "2     713021    6933186    7127253    7026525  ...     4722345     3381598   \n",
      "3    5098299    7062659    1687813    5319685  ...     1794944     2880647   \n",
      "4     663714    6579617    1528465     887785  ...     4400785     5212564   \n",
      "\n",
      "   predict 23  predict 24  predict 25  predict 26  predict 27  predict 28  \\\n",
      "0      645105     3571238     1346878     5629187     1917543     1966600   \n",
      "1     3412332     4734958     3046543     1953072     3580980     1777610   \n",
      "2     4586505     4438283     3654543     3425683     2867221     5215255   \n",
      "3     1860243      213542      284465     2775994     3949755     4575557   \n",
      "4     7098004     3450827     2555042     6423492     3409227     4969170   \n",
      "\n",
      "   predict 29  predict 30  \n",
      "0      154748     1599362  \n",
      "1     5840892     4655597  \n",
      "2     1358364     3896110  \n",
      "3      702039     5186904  \n",
      "4     2118677     5746641  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 数据加载 ---\n",
    "print(\"正在加载数据...\")\n",
    "try:\n",
    "    train_df = pd.read_csv('data/Antai_hackathon_train.csv')\n",
    "    test_df = pd.read_csv('data/dianshang_test.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"错误：请确保 train.csv 和 test_without_last.csv 文件在当前目录下！\")\n",
    "    # 模拟数据\n",
    "    train_df = pd.DataFrame({'buyer_admin_id': [1, 1, 1, 2, 2, 3, 3, 3], 'item_id': [10, 20, 30, 10, 40, 50, 10, 20]})\n",
    "    test_df = pd.DataFrame({'buyer_admin_id': [1, 2, 3], 'item_id': [30, 40, 20]})\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 步骤1: 构建以用户为行、物品为列的共现矩阵 (的稀疏表示)\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 我们不创建真实的m x n矩阵，而是创建一个字典，key是用户ID，value是该用户购买过的物品集合。\n",
    "# 这在功能上等价于存储了巨大矩阵中所有值为1的位置。\n",
    "print(\"步骤1: 正在构建用户-物品关系的稀疏表示...\")\n",
    "user_items_dict_train = train_df.groupby('buyer_admin_id')['item_id'].apply(set).to_dict()\n",
    "print(\"用户-物品关系构建完成。\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 步骤2: 计算共现矩阵两两列间的相似性\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 计算两列(item_i, item_j)的相似度，等价于计算 sim(i, j) = cos(vec_i, vec_j)\n",
    "# cos(vec_i, vec_j) = (vec_i · vec_j) / (||vec_i|| * ||vec_j||)\n",
    "# 其中：\n",
    "#   - vec_i · vec_j (点积) = 购买了i和j的共同用户数\n",
    "#   - ||vec_i|| (L2范数) = sqrt(购买了i的用户数)\n",
    "# 我们下面的代码就是为了计算这两个核心指标。\n",
    "\n",
    "print(\"步骤2: 正在计算物品间的相似度...\")\n",
    "\n",
    "# a. 计算点积 (dot product)，即分子部分：共同购买的用户数\n",
    "co_occurrence_matrix = defaultdict(lambda: defaultdict(int))\n",
    "# b. 计算范数 (norm) 的平方，即分母部分：每个物品的购买用户数\n",
    "item_popularity = defaultdict(int)\n",
    "\n",
    "# 通过遍历我们稀疏存储的用户-物品关系，来高效地完成计算\n",
    "for user, items in tqdm(user_items_dict_train.items(), desc=\"计算共现次数与物品热度\"):\n",
    "    for item in items:\n",
    "        # 每当一个物品在一个用户的集合里，它的购买用户数就+1\n",
    "        item_popularity[item] += 1\n",
    "    # 对于该用户购买过的每一对物品(i, j)，它们的共同购买用户数就+1\n",
    "    for i, j in combinations(items, 2):\n",
    "        co_occurrence_matrix[i][j] += 1\n",
    "        co_occurrence_matrix[j][i] += 1\n",
    "\n",
    "# c. 组合起来，计算最终的余弦相似度\n",
    "item_similarity_matrix = defaultdict(lambda: defaultdict(float))\n",
    "for i, related_items in tqdm(co_occurrence_matrix.items(), desc=\"计算最终的余弦相似度\"):\n",
    "    for j, count in related_items.items():\n",
    "        # 这就是余弦相似度公式的直接应用\n",
    "        # count = vec_i · vec_j\n",
    "        # item_popularity[i] = ||vec_i||^2\n",
    "        # item_popularity[j] = ||vec_j||^2\n",
    "        similarity = count / math.sqrt(item_popularity[i] * item_popularity[j])\n",
    "        item_similarity_matrix[i][j] = similarity\n",
    "\n",
    "print(\"物品相似度矩阵构建完成。\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# 步骤3 & 4: 获取用户正反馈物品，找出相似TopK，排序生成推荐列表\n",
    "# --------------------------------------------------------------------------------------\n",
    "print(\"步骤3 & 4: 正在为用户生成推荐列表...\")\n",
    "\n",
    "# 准备回退策略：全局热度榜单\n",
    "global_top_items_sorted = sorted(item_popularity.items(), key=lambda x: x[1], reverse=True)\n",
    "global_top_30_items = [item_id for item_id, pop in global_top_items_sorted[:30]]\n",
    "\n",
    "# 获取测试集用户的历史行为 (正反馈物品)\n",
    "user_items_dict_test = test_df.groupby('buyer_admin_id')['item_id'].apply(set).to_dict()\n",
    "all_test_users = test_df['buyer_admin_id'].unique()\n",
    "\n",
    "submission_data = []\n",
    "\n",
    "for user_id in tqdm(all_test_users, desc=\"生成推荐\"):\n",
    "    # 步骤3: 获取用户的正反馈物品列表\n",
    "    history_items = user_items_dict_test.get(user_id, set())\n",
    "    \n",
    "    candidate_scores = defaultdict(float)\n",
    "    \n",
    "    # 针对每一个正反馈物品，找出相似物品集合\n",
    "    for item_i in history_items:\n",
    "        # 这里为了效率，我们只考虑与item_i最相似的前N个物品\n",
    "        # 如果不加[:N]，则会考虑所有相似物品\n",
    "        for item_j, similarity in sorted(item_similarity_matrix.get(item_i, {}).items(), key=lambda x: x[1], reverse=True)[:50]:\n",
    "            # 过滤掉用户已经买过的\n",
    "            if item_j not in history_items:\n",
    "                # 累加相似度分数\n",
    "                candidate_scores[item_j] += similarity\n",
    "    \n",
    "    # 步骤4: 对相似物品集合中的物品，利用相似度分值进行排序\n",
    "    sorted_candidates = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    recommendations = [item_id for item_id, score in sorted_candidates]\n",
    "    \n",
    "    # 回退和补充逻辑\n",
    "    if len(recommendations) < 30:\n",
    "        rec_set = set(recommendations)\n",
    "        for popular_item in global_top_30_items:\n",
    "            if popular_item not in rec_set and popular_item not in history_items:\n",
    "                recommendations.append(popular_item)\n",
    "            if len(recommendations) >= 30:\n",
    "                break\n",
    "    \n",
    "    final_recommendations = recommendations[:30]\n",
    "    submission_data.append([user_id] + final_recommendations)\n",
    "\n",
    "# --- 保存提交文件 ---\n",
    "columns = ['buyer_admin_id'] + [f'predict {i+1}' for i in range(30)]\n",
    "submission_df = pd.DataFrame(submission_data, columns=columns)\n",
    "submission_filename = 'classic_item_cf_v2_baseline.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"\\n提交文件 '{submission_filename}' 已成功生成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f6230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
